{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3093155a-f407-4c9d-a910-62b10e908744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://docs.databricks.com/aws/en/oltp/query/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80c3b0d2-3574-4d73-8e31-2e8123efca0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U databricks-sdk\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4b2cca-7bc3-42fb-a246-b62a808f17ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import uuid\n",
    "import psycopg2\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from databricks.sdk import WorkspaceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "036a5432-160b-4162-8b24-72fa6c4717d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkspaceClient initialized as 'wc'.\n"
     ]
    }
   ],
   "source": [
    "wc = WorkspaceClient()\n",
    "print(\"WorkspaceClient initialized as 'wc'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844553b7-3397-4ce7-95d6-0ac0052f6981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "instance_name = \"juan-pg\"\n",
    "instance = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cdbcd34-8d05-4002-a2ae-57f2c016e354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_lakebase_instance(wc: WorkspaceClient, instance_name: str):\n",
    "    try:\n",
    "        logger.info(f\"Checking if Lakebase instance '{instance_name}' exists...\")\n",
    "        existing_instance = wc.database.get_database_instance(name=instance_name)\n",
    "        logger.info(\n",
    "            f\"Instance '{instance_name}' already exists. Returning existing instance.\"\n",
    "        )\n",
    "        if not existing_instance:\n",
    "            raise Exception(f\"Error: Instance '{instance_name}' not found.\")\n",
    "        return existing_instance\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error checking instance existence: {str(e)}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3be85dd-b2f4-4eaf-9984-536e93e539c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_or_create_lakebase_instance(\n",
    "    wc: WorkspaceClient,\n",
    "    instance_name: str,\n",
    "    capacity: str = \"CU_1\",\n",
    "    node_count: int = 1,\n",
    "    enable_readable_secondaries: bool = False,\n",
    "    retention_window_in_days: int = 7,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get or create a Lakebase instance.\n",
    "\n",
    "    Args:\n",
    "        instance_name: Name of the instance to create/get\n",
    "        capacity: Capacity of the instance (default: CU_1)\n",
    "        node_count: Number of nodes (default: 1)\n",
    "        enable_readable_secondaries: Whether to enable readable secondaries (default: False)\n",
    "        retention_window_in_days: Retention window in days (default: 7)\n",
    "\n",
    "    Returns:\n",
    "        Instance object\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if instance already exists\n",
    "    try:\n",
    "        existing_instance = get_lakebase_instance(wc, instance_name)\n",
    "        print(f\"Instance '{instance_name}' already exists. Returning existing instance.\")\n",
    "        return existing_instance\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # Instance doesn't exist, create it\n",
    "    logger.info(f\"Creating new Lakebase instance '{instance_name}'...\")\n",
    "    instance_create = wc.database.create_database_instance_and_wait(\n",
    "        name=instance_name,\n",
    "        capacity=capacity,\n",
    "        node_count=node_count,\n",
    "        enable_readable_secondaries=enable_readable_secondaries,\n",
    "        retention_window_in_days=retention_window_in_days,\n",
    "    )\n",
    "    if not instance_create:\n",
    "        raise Exception(f\"Error: Instance '{instance_name}' not created.\")\n",
    "    return instance_create\n",
    "\n",
    "def get_lakebase_token(wc: WorkspaceClient, instance_name: str):\n",
    "    try:\n",
    "        cred = wc.database.generate_database_credential(request_id=str(uuid.uuid4()), instance_names=[instance_name])\n",
    "        return cred.token\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating Lakebase token: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "def create_lakebase_connection(wc: WorkspaceClient, instance, db_name: str, user: str):\n",
    "    cred = get_lakebase_token(wc, instance['name'] if isinstance(instance, dict) else instance.name)\n",
    "    host = instance['read_write_dns'] if isinstance(instance, dict) else instance.read_write_dns\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        dbname=db_name,\n",
    "        user=user,\n",
    "        password=cred,\n",
    "        sslmode=\"require\"\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def grant_connect_to_database(wc: WorkspaceClient, instance, db_name: str, user: str):\n",
    "    conn = create_lakebase_connection(wc, instance, db_name, user)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"GRANT CONNECT ON DATABASE {db_name} TO {user}\")\n",
    "        conn.commit()\n",
    "    conn.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "312d7a7b-212a-434e-8d1c-8af0c4681975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 'juan-pg' already exists. Returning existing instance.\n",
      "Instance 'juan-pg' exists.\n",
      "Instance Name: juan-pg\n",
      "Instance ID: a3d637c2-ab56-40c5-9a93-1f9750535ba5\n",
      "State: DatabaseInstanceState.AVAILABLE\n",
      "Capacity: CU_2\n",
      "Node Count: 1\n",
      "Read-Write DNS: instance-a3d637c2-ab56-40c5-9a93-1f9750535ba5.database.cloud.databricks.com\n",
      "Read-Only DNS: instance-ro-a3d637c2-ab56-40c5-9a93-1f9750535ba5.database.cloud.databricks.com\n",
      "Enable Readable Secondaries: None\n",
      "Retention Window (days): 7\n",
      "Created At: 2025-09-18T01:45:55Z\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get \n",
    "try:\n",
    "    instance = get_or_create_lakebase_instance(wc, instance_name)\n",
    "    print(f\"Instance '{instance_name}' exists.\")\n",
    "    print(f\"Instance Name: {instance.name}\")\n",
    "    print(f\"Instance ID: {instance.uid}\")\n",
    "    print(f\"State: {instance.state}\")\n",
    "    print(f\"Capacity: {instance.capacity}\")\n",
    "    print(f\"Node Count: {instance.effective_node_count}\")\n",
    "    print(f\"Read-Write DNS: {instance.read_write_dns}\")\n",
    "    print(f\"Read-Only DNS: {instance.read_only_dns}\")\n",
    "    print(f\"Enable Readable Secondaries: {instance.enable_readable_secondaries}\")\n",
    "    print(f\"Retention Window (days): {instance.effective_retention_window_in_days}\")\n",
    "    print(f\"Created At: {instance.creation_time}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving instance '{instance_name}': {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12bddd87-d07e-4a6a-85a7-11d18b7f6d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token for instance 'juan-pg': \n",
      " eyJraWQiOiJkZmJjOWVmMThjZTQ2ZTlhMDg2NWZmYzlkODkxYzJmMjg2NmFjMDM3MWZiNDlmOTdhMDg1MzBjNWYyODU3ZTg4IiwidHlwIjoiYXQrand0IiwiYWxnIjoiUlMyNTYifQ.eyJjbGllbnRfaWQiOiJkYi1kYXRhYmFzZS1jcmVkZW50aWFsIiwic2NvcGUiOiJpYW0uY3VycmVudC11c2VyOnJlYWQgaWFtLmdyb3VwczpyZWFkIGlhbS5zZXJ2aWNlLXByaW5jaXBhbHM6cmVhZCBpYW0udXNlcnM6cmVhZCIsImlzcyI6Imh0dHBzOi8vZTItZGVtby1maWVsZC1lbmcuY2xvdWQuZGF0YWJyaWNrcy5jb20vb2lkYyIsImF1ZCI6IjE0NDQ4MjgzMDU4MTA0ODUiLCJzdWIiOiJqdWFuLmxhbWFkcmlkQGRhdGFicmlja3MuY29tIiwiaWF0IjoxNzU4ODE3ODkwLCJleHAiOjE3NTg4MjE0OTAsImp0aSI6IjM0NTk0NjZhLTQ0OGQtNDBhNC05NDA3LWY1YjY0MjM5MDY3NiJ9.MGny3pw9BM48CW48k9jJe-DUMTCYUgIQ7qxGGH4ab3y3Ce9RxOvOsmZbbH463e6hUB75LOYIlaKQJHOOsJygclsaaq_VDa4i3n8NzF_NjeZb5Fmb2VRBNuQaaKUvFO5dkSa4y1ejD4-gUbr2Th01M2n6LZvtOHL0EoJBDWnjwXU5e7B67VZ_NTSges_de3st_YL9dzUcyMtZQLafniDoN8HOhWlEKy6LWLgDSWBOf_8itrfGzoD90zhJpW0-9AwB4oQo1o5A52im_CJxLbgWdAC6r6p5FL4WJFhu8tZw0nVapnAUaSZWl7_R5PMK4ASRDTlDCdHzEW_SUafPAeqBzw\n"
     ]
    }
   ],
   "source": [
    "instance_token = get_lakebase_token(wc, instance_name)\n",
    "print(f\"Token for instance '{instance_name}': \\n {instance_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "lakebase",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
